{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# data_d25a.ipynb\n",
    "1. For GMSL and RSL at gauges, save fusion, high-end, low-end, and central projections for 2020â€“2100, and also gauge info.\n",
    "2. For cities near a gauge, save city info, gauge info, high-end, low-end, and central projections for 2100.\n",
    "\n",
    "Author: Benjamin S. Grandey."
   ],
   "id": "ac230d2e922e41c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:47.483052Z",
     "start_time": "2025-02-05T09:08:47.322242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import d25a\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "5c52dfd4b92a9753",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:47.487419Z",
     "start_time": "2025-02-05T09:08:47.485821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get start datetime\n",
    "start_dt = datetime.datetime.now()"
   ],
   "id": "48924b4bec9cd18b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:47.567925Z",
     "start_time": "2025-02-05T09:08:47.555960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print package versions\n",
    "print(d25a.get_watermark())"
   ],
   "id": "c523aa565d8149a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.16\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "matplotlib: 3.10.0\n",
      "numpy     : 2.2.2\n",
      "pandas    : 2.2.3\n",
      "seaborn   : 0.13.2\n",
      "xarray    : 2025.1.1\n",
      "\n",
      "conda environment: d25a-rsl-fusion\n",
      "\n",
      "Compiler    : Clang 18.1.8 \n",
      "OS          : Darwin\n",
      "Release     : 22.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:47.576287Z",
     "start_time": "2025-02-05T09:08:47.573623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make output directories if they don't exist\n",
    "for data_dir in (d25a.DATA_DIR, d25a.DATA_DIR / 'gmsl', d25a.DATA_DIR / 'gauges', d25a.DATA_DIR / 'cities'):\n",
    "    if not data_dir.exists():\n",
    "        data_dir.mkdir()"
   ],
   "id": "f040b339dacecd5f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. GMSL and RSL at gauges",
   "id": "9648d1c0a1eb8416"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1a. Identify gauges with missing RSL data\n",
    "These gauges will be dropped."
   ],
   "id": "5458452fac5c4b2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:48.565945Z",
     "start_time": "2025-02-05T09:08:47.588752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read fusion RSL data for one scenario\n",
    "qfs_da = d25a.get_sl_qfs(workflow='fusion_1e+2e', gmsl_rsl_novlm='rsl', scenario='ssp585').copy()\n",
    "# Identify locations with missing data\n",
    "missing_gauges = qfs_da.where(qfs_da.isnull(), drop=True).locations.data\n",
    "# Print some information about these gauges\n",
    "print(f'{len(missing_gauges)} gauges have missing RSL data:')\n",
    "for gauge_id in missing_gauges:\n",
    "    gauge_info = d25a.get_gauge_info(gauge=gauge_id)\n",
    "    print(f\"{gauge_id}, {gauge_info['gauge_name']}, {gauge_info['country']}\")"
   ],
   "id": "bcaa3fef5d0ba504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 gauges have missing RSL data:\n",
      "126, TROIS-RIVIERES, CANADA\n",
      "137, PORT-SAINT-FRANCOIS, CANADA\n",
      "144, BATISCAN, CANADA\n",
      "173, QUEBEC, CANADA\n",
      "192, NEUVILLE, CANADA\n",
      "201, DESCHAILLONS, CANADA\n",
      "387, GRONDINES, CANADA\n",
      "951, PORTNEUF, CANADA\n",
      "999, ST-FRANCOIS, CANADA\n",
      "1005, CHAMPLAIN, CANADA\n",
      "1219, TADOUSSAC, CANADA\n",
      "1244, ST-JOSEPH-DE-LA-RIVE, CANADA\n",
      "1392, PORT-ALFRED, CANADA\n",
      "1798, BECANCOUR, CANADA\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1b. Save fusion, high-end, and low-end projections",
   "id": "bb4e935e71fe605c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:50.285223Z",
     "start_time": "2025-02-05T09:08:48.570186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loop over GMSL, RSL, and RSL without VLM component\n",
    "for gmsl_rsl_novlm in ('gmsl', 'rsl', 'novlm'):\n",
    "    # Output directory\n",
    "    if gmsl_rsl_novlm == 'gmsl':\n",
    "        out_dir = d25a.DATA_DIR / 'gmsl'\n",
    "    else:\n",
    "        out_dir = d25a.DATA_DIR / 'gauges'\n",
    "    # Loop over two scenarios\n",
    "    for scenario in ['ssp585', 'ssp126']:\n",
    "        # Derive fusion projection\n",
    "        qfs_da = d25a.get_sl_qfs(workflow='fusion_1e+2e', gmsl_rsl_novlm=gmsl_rsl_novlm, scenario=scenario).copy()\n",
    "        # Drop gauges with missing RSL data\n",
    "        if gmsl_rsl_novlm != 'gmsl':\n",
    "            for gauge_id in missing_gauges:\n",
    "                qfs_da.sel(locations=gauge_id).data[:] = np.nan  # this changes novlm data to also be NaN\n",
    "            qfs_da = qfs_da.dropna(dim='locations')\n",
    "        # Save fusion projection\n",
    "        out_fn = out_dir / f'{gmsl_rsl_novlm}_fusion_{scenario}_d25a.nc'\n",
    "        if gmsl_rsl_novlm == 'gmsl':\n",
    "            print(f'Writing {out_fn.name}')\n",
    "        else:\n",
    "            print(f'Writing {out_fn.name} ({len(qfs_da.locations)} gauges)')\n",
    "        qfs_da.to_netcdf(out_fn)\n",
    "        # Derive and save high-end or low-end projection, depending on scenario\n",
    "        if scenario == 'ssp585':\n",
    "            high_da = qfs_da.sel(quantiles=0.95).squeeze()\n",
    "            out_fn = out_dir / f'{gmsl_rsl_novlm}_high_d25a.nc'\n",
    "            print(f'Writing {out_fn.name}')\n",
    "            high_da.to_netcdf(out_fn)\n",
    "        elif scenario == 'ssp126':\n",
    "            low_da = qfs_da.sel(quantiles=0.05).squeeze()\n",
    "            out_fn = out_dir / f'{gmsl_rsl_novlm}_low_d25a.nc'\n",
    "            print(f'Writing {out_fn.name}')\n",
    "            low_da.to_netcdf(out_fn)"
   ],
   "id": "a092f8568d5bcb76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gmsl_fusion_ssp585_d25a.nc\n",
      "Writing gmsl_high_d25a.nc\n",
      "Writing gmsl_fusion_ssp126_d25a.nc\n",
      "Writing gmsl_low_d25a.nc\n",
      "Writing rsl_fusion_ssp585_d25a.nc (1016 gauges)\n",
      "Writing rsl_high_d25a.nc\n",
      "Writing rsl_fusion_ssp126_d25a.nc (1016 gauges)\n",
      "Writing rsl_low_d25a.nc\n",
      "Writing novlm_fusion_ssp585_d25a.nc (1016 gauges)\n",
      "Writing novlm_high_d25a.nc\n",
      "Writing novlm_fusion_ssp126_d25a.nc (1016 gauges)\n",
      "Writing novlm_low_d25a.nc\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1c. Save central projection\n",
    "Defined as median of medium confidence mean under SSP2-4.5."
   ],
   "id": "daf737c88801b68f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:08:50.919942Z",
     "start_time": "2025-02-05T09:08:50.344325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loop over GMSL/RSL and scenarios\n",
    "for gmsl_rsl_novlm in ('gmsl', 'rsl', 'novlm'):\n",
    "    # Output directory\n",
    "    if gmsl_rsl_novlm == 'gmsl':\n",
    "        out_dir = d25a.DATA_DIR / 'gmsl'\n",
    "    else:\n",
    "        out_dir = d25a.DATA_DIR / 'gauges'\n",
    "    # Derive medium confidence mean under SSP2-4.5\n",
    "    qfs_da = d25a.get_sl_qfs(workflow='mean_1e+2e', gmsl_rsl_novlm=gmsl_rsl_novlm, scenario='ssp245').copy()\n",
    "    # Drop locations with NaN\n",
    "    if gmsl_rsl_novlm != 'gmsl':\n",
    "        # Drop gauges with missing RSL data\n",
    "        if gmsl_rsl_novlm != 'gmsl':\n",
    "            for gauge_id in missing_gauges:\n",
    "                qfs_da.sel(locations=gauge_id).data[:] = np.nan  # this changes novlm data to also be NaN\n",
    "            qfs_da = qfs_da.dropna(dim='locations')\n",
    "    # Derive and Save central projection\n",
    "    central_da = qfs_da.sel(quantiles=0.5).squeeze()\n",
    "    out_fn = out_dir / f'{gmsl_rsl_novlm}_central_d25a.nc'\n",
    "    print(f'Writing {out_fn.name}')\n",
    "    central_da.to_netcdf(out_fn)"
   ],
   "id": "f4a39d1e662d8ced",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gmsl_central_d25a.nc\n",
      "Writing rsl_central_d25a.nc\n",
      "Writing novlm_central_d25a.nc\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1d. Save gauge information",
   "id": "726d330a38fdfbbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:09:16.840105Z",
     "start_time": "2025-02-05T09:08:50.929810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataFrame to hold gauge information\n",
    "gauge_info_df = pd.DataFrame(columns=['gauge_id', 'gauge_name', 'lat', 'lon', 'country'])\n",
    "# Loop over locations for which projections are available\n",
    "qfs_da = d25a.get_sl_qfs().copy()\n",
    "for location in qfs_da.locations.data:\n",
    "    if location not in missing_gauges:\n",
    "        # Get information about this gauge and save to DataFrame\n",
    "        gauge_info = d25a.get_gauge_info(location)\n",
    "        gauge_info_df.loc[len(gauge_info_df)] = gauge_info\n",
    "# Index by gauge_id\n",
    "gauge_info_df = gauge_info_df.set_index('gauge_id')\n",
    "# Save to CSV\n",
    "out_fn = d25a.DATA_DIR / 'gauges' / f'gauge_info_d25a.csv'\n",
    "print(f'Writing {out_fn.name} ({len(gauge_info_df)} gauges)')\n",
    "gauge_info_df.to_csv(out_fn)"
   ],
   "id": "220bb474c0f0299c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gauge_info_d25a.csv (1016 gauges)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Identify large cities with a tide gauge nearby\n",
    "1. Urban agglomeration has a population of at least 10 million in 2025.\n",
    "2. Select nearest tide gauge within a maximum distance of 100 km."
   ],
   "id": "f71b2387f32baf01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:09:16.866192Z",
     "start_time": "2025-02-05T09:09:16.863824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Read World Urbanisation Prospects 2018 data\n",
    "# cities_df = pd.read_excel('data_wup18/WUP2018-F12-Cities_Over_300K.xls', header=16, usecols='C:E,G,H,X', index_col=None)\n",
    "# cities_df = cities_df.rename(columns={'Country or area': 'city_country', 'City Code': 'city_code',\n",
    "#                                       'Urban Agglomeration': 'city_name', 'Latitude': 'city_lat', 'Longitude': 'city_lon',\n",
    "#                                       2025: 'population_2025'})\n",
    "# cities_df = cities_df.set_index('city_code')\n",
    "# # Select cities with population > 10 million (ie > 10,000 thousand) in 2025\n",
    "# cities_df = cities_df.where(cities_df['population_2025'] > 10000).dropna().sort_values(by='population_2025', ascending=False)\n",
    "# print(f'{len(cities_df)} cities have a population > 10 million in 2025.')\n",
    "# # Loop over these cities and find nearest tide gauge and distance\n",
    "# for index, row_ser in cities_df.iterrows():\n",
    "#     lat0 = row_ser['city_lat']  # latitude of city\n",
    "#     lon0 = row_ser['city_lon']  # longitude of city\n",
    "#     temp_df = gauge_info_df.copy()  # copy tide gauge data\n",
    "#     temp_df['distance'] = 6378 * np.arccos(  # calculate great-circle distance between city and all available gauges\n",
    "#         np.sin(np.radians(lat0)) * np.sin(np.radians(temp_df['lat'])) +\n",
    "#         np.cos(np.radians(lat0)) * np.cos(np.radians(temp_df['lat'])) * np.cos(np.radians(temp_df['lon'] - lon0)))\n",
    "#     temp_df['distance'] = temp_df['distance'].round(0).astype(int)  # round to nearest km\n",
    "#     temp_df = temp_df.sort_values(by=['distance']).reset_index()  # sort by distance\n",
    "#     temp_df = temp_df.rename(columns={'lat': 'gauge_lat', 'lon': 'gauge_lon'})\n",
    "#     for col in ['gauge_id', 'gauge_name', 'gauge_lat', 'gauge_lon', 'distance']:\n",
    "#         cities_df.loc[index, col] = temp_df.loc[0, col]  # save gauge info to cities_df\n",
    "# # Identify shorter name for cities with a long name\n",
    "# for index, row_ser in cities_df.iterrows():\n",
    "#     short_name = row_ser['city_name']  # use full name by default\n",
    "#     if short_name.split(' (')[0] in ['Mumbai', 'Kolkata']:  # cases to use name outside parentheses\n",
    "#         short_name = short_name.split(' (')[0]\n",
    "#     elif '(' in short_name:  # cases to use name within parentheses\n",
    "#         short_name = short_name.split(' (')[-1].rstrip(')')\n",
    "#     elif ',' in short_name:  # cases to use name before comma\n",
    "#         short_name = short_name.split(',')[0]\n",
    "#     elif '-' in short_name:  # cases to use name before hyphen\n",
    "#         short_name = short_name.split('-')[0]\n",
    "#     cities_df.loc[index, 'city_short'] = short_name\n",
    "# # Save to CSV\n",
    "# out_fn = d25a.DATA_DIR / f'cities_d25a.csv'\n",
    "# print(f'Writing {out_fn.name}')\n",
    "# cities_df.to_csv(out_fn)"
   ],
   "id": "f6bb1f1640585d7e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T09:09:16.885584Z",
     "start_time": "2025-02-05T09:09:16.883171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get end datetime\n",
    "end_dt = datetime.datetime.now()\n",
    "# Calculate run timedelta\n",
    "run_td = end_dt - start_dt\n",
    "# Print timing information\n",
    "print(f\"Start:     {start_dt.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"End:       {end_dt.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Wall time: {run_td.seconds} s\")"
   ],
   "id": "b82442286e16acd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:     2025-02-05 17:08:47\n",
      "End:       2025-02-05 17:09:16\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d25a-rsl-fusion]",
   "language": "python",
   "name": "conda-env-d25a-rsl-fusion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
